<!DOCTYPE html>
<html lang="en" dir="ltr">
    <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content="MIT researchers conducted a study showing that large language models (LLMs) used for treatment recommendations in healthcare can be influenced by nonclinical factors in patient messages, leading to inaccurate recommendations, especially for female patients. The study highlighted the need for auditing LLMs before deploying them in healthcare. The researchers found that LLMs&rsquo; judgment was affected by factors like typos, extra white space, missing gender markers, and informal language used in patient messages. The study revealed inconsistencies and disagreements among LLMs when fed altered patient data, with LLMs more likely to recommend self-management over seeking medical care in response to certain text variations. These findings emphasize the importance of rigorously evaluating LLMs before using them for critical healthcare applications.\n">
<title>LLMs factor in unrelated information when recommending medical treatments</title>

<link rel='canonical' href='http://localhost:1313/p/llms-factor-in-unrelated-information-when-recommending-medical-treatments/'>

<link rel="stylesheet" href="/scss/style.min.ee36f3b1c262e9ee31e77636bd21600aa5fbc08e33d66a40000d925ec90e18a3.css"><meta property='og:title' content="LLMs factor in unrelated information when recommending medical treatments">
<meta property='og:description' content="MIT researchers conducted a study showing that large language models (LLMs) used for treatment recommendations in healthcare can be influenced by nonclinical factors in patient messages, leading to inaccurate recommendations, especially for female patients. The study highlighted the need for auditing LLMs before deploying them in healthcare. The researchers found that LLMs&rsquo; judgment was affected by factors like typos, extra white space, missing gender markers, and informal language used in patient messages. The study revealed inconsistencies and disagreements among LLMs when fed altered patient data, with LLMs more likely to recommend self-management over seeking medical care in response to certain text variations. These findings emphasize the importance of rigorously evaluating LLMs before using them for critical healthcare applications.\n">
<meta property='og:url' content='http://localhost:1313/p/llms-factor-in-unrelated-information-when-recommending-medical-treatments/'>
<meta property='og:site_name' content='Example Site'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:published_time' content='2025-06-30T10:26:02&#43;08:00'/><meta property='article:modified_time' content='2025-06-30T10:26:02&#43;08:00'/>
<meta name="twitter:title" content="LLMs factor in unrelated information when recommending medical treatments">
<meta name="twitter:description" content="MIT researchers conducted a study showing that large language models (LLMs) used for treatment recommendations in healthcare can be influenced by nonclinical factors in patient messages, leading to inaccurate recommendations, especially for female patients. The study highlighted the need for auditing LLMs before deploying them in healthcare. The researchers found that LLMs&rsquo; judgment was affected by factors like typos, extra white space, missing gender markers, and informal language used in patient messages. The study revealed inconsistencies and disagreements among LLMs when fed altered patient data, with LLMs more likely to recommend self-management over seeking medical care in response to certain text variations. These findings emphasize the importance of rigorously evaluating LLMs before using them for critical healthcare applications.\n">
    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended">
    

            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/p/llms-factor-in-unrelated-information-when-recommending-medical-treatments/">LLMs factor in unrelated information when recommending medical treatments</a>
        </h2>
    
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Jun 30, 2025</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    1 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <p><strong>摘要：</strong></p>
<p>一项由麻省理工学院研究人员进行的研究发现，大型语言模型（LLM）在进行治疗建议时可能会受到患者信息中的非临床信息的影响，例如拼写错误、额外的空格、缺少性别标记或使用不确定、夸张和非正式语言。他们发现，对消息进行风格或语法更改会增加LLM建议患者自行管理其报告的健康状况的可能性，而不是前来就诊，即使该患者应该寻求医疗护理。</p>
<p>研究人员还发现，这些文本中的非临床变化更有可能改变模型对女性患者的治疗建议，导致建议女性患者不要寻求医疗护理的比例更高，而这与人类医生的建议相左。</p>
<p>研究人员认为，这些发现表明LLMs以前未知的方式考虑非临床信息进行临床决策。他们指出，这突显了在LLMs被用于高风险应用（如制定治疗建议）之前需要进行更严格的研究的必要性。</p>
<p>研究人员设计了一项研究，通过更改模型的输入数据，如交换或删除性别标记、添加丰富多彩或不确定的语言，或在患者消息中插入额外的空格和拼写错误，来探讨非临床信息如何影响模型的判断。研究结果显示，LLMs在处理经过修改的数据时存在治疗建议不一致和显著分歧的情况。对女性患者的错误建议比例较高，而这些变化对人类临床医生的准确性则没有影响。</p>
<p>研究人员计划通过设计自然语言扰动来捕捉其他弱势群体并更好地模拟真实消息，以扩展这项工作。他们还想探讨LLMs如何从临床文本中推断性别。</p>

</section>


    <footer class="article-footer">
    

    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    </footer>


    
</article>

    

    

     
    
        
    <div class="disqus-container">
    <div id="disqus_thread"></div>
<script>
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "hugo-theme-stack" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>

<style>
    .disqus-container {
        background-color: var(--card-background);
        border-radius: var(--card-border-radius);
        box-shadow: var(--shadow-l1);
        padding: var(--card-padding);
    }
</style>

<script>
    window.addEventListener('onColorSchemeChange', (e) => {
        if (typeof DISQUS == 'object') {
            DISQUS.reset({
                reload: true
            });
        }
    })
</script>

    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2020 - 
        
        2025 Example Person
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.30.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.95f9844a5e2c392e19771fe007a767f265494f26f8f3205d1d4681b077de59b1.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
